{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a3df3d3-bdde-420b-8635-b738377eb01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ XGBoost available, version: 3.0.1\n",
      "=== XGBoost Time Series Binary Classification Detailed Analysis ===\n",
      "\n",
      "1. Loading data...\n",
      "Trying to read file using openpyxl engine...\n",
      "✓ Successfully read data using openpyxl\n",
      "Successfully read data, shape: (375, 7)\n",
      "Column names: ['ID', 'X1', 'X2', 'X3', 'X4', 'X5', 'label']\n",
      "\n",
      "Data preview:\n",
      "   ID       X1       X2       X3       X4       X5  label\n",
      "0   1   910.23  2174.87  3399.19  4568.75  5669.20      1\n",
      "1   2   840.10  2221.61  3554.34  4828.21  6014.50      1\n",
      "2   3   811.46  2028.56  3192.89  4306.80  5343.23      1\n",
      "3   4  2413.83  5045.10  6452.97  7616.88  8631.15      1\n",
      "4   5  2442.67  5111.87  6512.67  7653.70  8638.73      1\n",
      "\n",
      "Final data dimensions: X=(375, 5), y=(375,)\n",
      "Label distribution: Positive=263 (70.1%), Negative=112 (29.9%)\n",
      "Data dimensions: X=(375, 5), y=(375,)\n",
      "Label distribution: Positive=263 (70.1%), Negative=112 (29.9%)\n",
      "\n",
      "2. Data preprocessing and splitting...\n",
      "Training set size: 225\n",
      "Validation set size: 75\n",
      "Test set size: 75\n",
      "Training set positive ratio: 0.702\n",
      "Validation set positive ratio: 0.707\n",
      "Test set positive ratio: 0.693\n",
      "\n",
      "3. Creating and training XGBoost model...\n",
      "Starting training XGBoost Detailed Analysis Model...\n",
      "Training samples: 225, Validation samples: 75\n",
      "Training error: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "✓ Completed using basic training method\n",
      "\n",
      "Validation performance:\n",
      "Accuracy: 0.9867\n",
      "AUC: 0.9996\n",
      "F1-score: 0.9905\n",
      "\n",
      "Feature importance:\n",
      "X4 (4-minute): 0.4205\n",
      "X5 (5-minute): 0.3815\n",
      "X3 (3-minute): 0.1420\n",
      "X2 (2-minute): 0.0336\n",
      "X1 (1-minute): 0.0225\n",
      "\n",
      "4. Performing cross validation...\n",
      "\n",
      "Performing 5-fold cross validation...\n",
      "Cross-validation AUC: 0.9970 (+/- 0.0120)\n",
      "\n",
      "5. Final test set evaluation...\n",
      "\n",
      "=== Final Test Results ===\n",
      "Test Accuracy: 1.0000\n",
      "Test AUC: 1.0000\n",
      "Test F1-Score: 1.0000\n",
      "Cross-validation AUC Mean: 0.9970 (±0.0060)\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00        23\n",
      "    Positive       1.00      1.00      1.00        52\n",
      "\n",
      "    accuracy                           1.00        75\n",
      "   macro avg       1.00      1.00      1.00        75\n",
      "weighted avg       1.00      1.00      1.00        75\n",
      "\n",
      "\n",
      "6. Generating detailed visualization analysis...\n",
      "Plotting comprehensive analysis charts...\n",
      "Saving individual plots to xgboost_plots/ directory...\n",
      "✓ Saved: 02_feature_importance.svg\n",
      "✓ Saved: 03_roc_curves.svg\n",
      "✓ Saved: 04_precision_recall_curves.svg\n",
      "✓ Saved: 05_confusion_matrix.svg\n",
      "✓ Saved: 06-1_Negative_probability_distribution.svg\n",
      "✓ Saved: 06-2_Positive_probability_distribution.svg\n",
      "✓ Saved: 06_probability_distribution.svg\n",
      "✓ Saved: 07_performance_radar.svg\n",
      "✓ Saved: 08_learning_curve.svg\n",
      "✓ Saved: 09_feature_correlation.svg\n",
      "✓ Saved: 10_tree_or_importance_pie.svg\n",
      "Plotting training process analysis...\n",
      "No training history data available for visualization\n",
      "Plotting feature interaction analysis...\n",
      "✓ Saved: 15_feature_importance_ranking.svg\n",
      "✓ Saved: 16_feature_distribution.svg\n",
      "✓ Saved: 17_correlation_network.svg\n",
      "✓ Saved: 18_cumulative_importance.svg\n",
      "Creating performance report table...\n",
      "✓ Saved: 19_performance_report_table.svg\n",
      "\n",
      "=== XGBoost Model Analysis Summary ===\n",
      "✓ Model achieved AUC of 1.000 on test set, performance is Excellent\n",
      "✓ Cross-validation results are stable, AUC standard deviation is 0.006\n",
      "✓ Most important feature is X4 (4-minute), importance: 0.420\n",
      "\n",
      "Feature Importance Ranking:\n",
      "1. X4 (4-minute): 0.420\n",
      "2. X5 (5-minute): 0.381\n",
      "3. X3 (3-minute): 0.142\n",
      "4. X2 (2-minute): 0.034\n",
      "5. X1 (1-minute): 0.022\n",
      "\n",
      "Recommend using this XGBoost model for time series binary classification prediction\n",
      "Model training completed, ready for new data prediction\n",
      "\n",
      "All plots have been saved as individual SVG files in the 'xgboost_plots' directory\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, \n",
    "                           roc_auc_score, roc_curve, precision_recall_curve, \n",
    "                           average_precision_score, f1_score, precision_score, recall_score)\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# XGBoost import\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "    print(\"✓ XGBoost available, version:\", xgb.__version__)\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"✗ XGBoost not installed, please run: pip install xgboost\")\n",
    "    exit()\n",
    "\n",
    "# Set English font support\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans', 'Liberation Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate mock dataset (375 samples, 5 time features)\n",
    "def generate_sample_data():\n",
    "    \"\"\"Generate simulated time series data\"\"\"\n",
    "    n_samples = 375\n",
    "    \n",
    "    # Generate basic time features\n",
    "    X1 = np.random.normal(10, 2, n_samples)  # 1-minute feature\n",
    "    X2 = X1 + np.random.normal(0, 1, n_samples)  # 2-minute feature (correlated with X1)\n",
    "    X3 = X2 + np.random.normal(0, 1.5, n_samples)  # 3-minute feature\n",
    "    X4 = X3 + np.random.normal(0, 1, n_samples)  # 4-minute feature\n",
    "    X5 = X4 + np.random.normal(0, 2, n_samples)  # 5-minute feature\n",
    "    \n",
    "    # Create feature matrix\n",
    "    X = np.column_stack([X1, X2, X3, X4, X5])\n",
    "    \n",
    "    # Generate labels (based on feature combination)\n",
    "    trend = (X5 - X1) / 4  # Calculate trend\n",
    "    mean_value = np.mean(X, axis=1)  # Mean value\n",
    "    \n",
    "    # Generate labels based on trend and mean value\n",
    "    prob_positive = 1 / (1 + np.exp(-(0.3 * trend + 0.1 * mean_value - 2)))\n",
    "    y = np.random.binomial(1, prob_positive, n_samples)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def load_excel_data(file_path='DATA-5.xlsx', sheet_name=0):\n",
    "    \"\"\"Load data from Excel file\"\"\"\n",
    "    try:\n",
    "        # Try different engines to read Excel file\n",
    "        engines = ['openpyxl', 'xlrd']\n",
    "        df = None\n",
    "        \n",
    "        for engine in engines:\n",
    "            try:\n",
    "                print(f\"Trying to read file using {engine} engine...\")\n",
    "                df = pd.read_excel(file_path, sheet_name=sheet_name, engine=engine)\n",
    "                print(f\"✓ Successfully read data using {engine}\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"✗ {engine} engine failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if df is None:\n",
    "            raise Exception(\"All engines failed to read the file\")\n",
    "            \n",
    "        print(f\"Successfully read data, shape: {df.shape}\")\n",
    "        print(f\"Column names: {list(df.columns)}\")\n",
    "        \n",
    "        # Display first few rows\n",
    "        print(\"\\nData preview:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_values = df.isnull().sum()\n",
    "        if missing_values.any():\n",
    "            print(\"\\nMissing values statistics:\")\n",
    "            print(missing_values[missing_values > 0])\n",
    "            print(\"Removing rows with missing values...\")\n",
    "            df = df.dropna()\n",
    "            print(f\"Shape after removal: {df.shape}\")\n",
    "        \n",
    "        # Automatically identify feature columns and label column\n",
    "        feature_cols = []\n",
    "        label_col = None\n",
    "        \n",
    "        # Look for X1-X5 feature columns (case insensitive)\n",
    "        for col in df.columns:\n",
    "            col_str = str(col).strip().upper()\n",
    "            if col_str in ['X1', 'X2', 'X3', 'X4', 'X5']:\n",
    "                feature_cols.append(col)\n",
    "        \n",
    "        # Sort by X1,X2,X3,X4,X5 order\n",
    "        feature_order = {'X1': 1, 'X2': 2, 'X3': 3, 'X4': 4, 'X5': 5}\n",
    "        feature_cols.sort(key=lambda x: feature_order.get(str(x).strip().upper(), 999))\n",
    "        \n",
    "        # Look for label column\n",
    "        for col in df.columns:\n",
    "            col_str = str(col).strip().lower()\n",
    "            if col_str in ['label', 'y', 'target', 'class', 'lable']:\n",
    "                label_col = col\n",
    "                break\n",
    "        \n",
    "        # If standard column names not found, smart guess\n",
    "        if len(feature_cols) != 5:\n",
    "            print(f\"\\nOnly found {len(feature_cols)} standard feature columns: {feature_cols}\")\n",
    "            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            if len(numeric_cols) >= 5:\n",
    "                feature_cols = numeric_cols[:5]\n",
    "                print(f\"Auto-selecting first 5 numeric columns as features: {feature_cols}\")\n",
    "            else:\n",
    "                return None, None\n",
    "        \n",
    "        if label_col is None:\n",
    "            remaining_cols = [col for col in df.columns if col not in feature_cols]\n",
    "            if remaining_cols:\n",
    "                label_col = remaining_cols[0]\n",
    "                print(f\"Auto-selecting column as label: {label_col}\")\n",
    "            else:\n",
    "                return None, None\n",
    "        \n",
    "        # Extract features and labels\n",
    "        X = df[feature_cols].values\n",
    "        y = df[label_col].values\n",
    "        \n",
    "        # Process labels\n",
    "        unique_labels = np.unique(y)\n",
    "        if set(unique_labels) == {0, 1} or set(unique_labels) == {0.0, 1.0}:\n",
    "            y = y.astype(int)\n",
    "        elif len(unique_labels) == 2:\n",
    "            min_val, max_val = min(unique_labels), max(unique_labels)\n",
    "            y = (y == max_val).astype(int)\n",
    "        else:\n",
    "            return None, None\n",
    "        \n",
    "        print(f\"\\nFinal data dimensions: X={X.shape}, y={y.shape}\")\n",
    "        print(f\"Label distribution: Positive={np.sum(y)} ({100*np.mean(y):.1f}%), Negative={len(y)-np.sum(y)} ({100*(1-np.mean(y)):.1f}%)\")\n",
    "        \n",
    "        return X, y\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found {file_path}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel file: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def prepare_data(X, y):\n",
    "    \"\"\"Data standardization and split into train/validation/test sets\"\"\"\n",
    "    # Ensure input is numpy array format\n",
    "    if hasattr(X, 'values'):\n",
    "        X = X.values\n",
    "    if hasattr(y, 'values'):\n",
    "        y = y.values\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # First split into train and temp sets (test + validation)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Then split temp set into validation and test sets\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(f\"Training set size: {X_train_scaled.shape[0]}\")\n",
    "    print(f\"Validation set size: {X_val_scaled.shape[0]}\")\n",
    "    print(f\"Test set size: {X_test_scaled.shape[0]}\")\n",
    "    print(f\"Training set positive ratio: {np.mean(y_train):.3f}\")\n",
    "    print(f\"Validation set positive ratio: {np.mean(y_val):.3f}\")\n",
    "    print(f\"Test set positive ratio: {np.mean(y_test):.3f}\")\n",
    "    \n",
    "    return (X_train_scaled, X_val_scaled, X_test_scaled, \n",
    "            y_train, y_val, y_test, scaler)\n",
    "\n",
    "class XGBoostDetailedModel:\n",
    "    \"\"\"Enhanced XGBoost model with detailed training process monitoring and visualization\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = xgb.XGBClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            eval_metric='logloss',\n",
    "            use_label_encoder=False\n",
    "        )\n",
    "        self.name = \"XGBoost Detailed Analysis Model\"\n",
    "        self.feature_importance = None\n",
    "        self.training_history = {}\n",
    "        self.feature_names = ['X1 (1-minute)', 'X2 (2-minute)', 'X3 (3-minute)', 'X4 (4-minute)', 'X5 (5-minute)']\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val, y_val):\n",
    "        \"\"\"Train model and record detailed process\"\"\"\n",
    "        print(f\"Starting training {self.name}...\")\n",
    "        print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")\n",
    "        \n",
    "        # Create validation set\n",
    "        eval_set = [(X_train, y_train), (X_val, y_val)]\n",
    "        eval_names = ['train', 'validation']\n",
    "        \n",
    "        try:\n",
    "            # Train with early stopping\n",
    "            self.model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=eval_set,\n",
    "                early_stopping_rounds=20,\n",
    "                verbose=10\n",
    "            )\n",
    "            print(\"✓ Training completed\")\n",
    "            \n",
    "            # Get training history\n",
    "            self.training_history = self.model.evals_result()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Training error: {e}\")\n",
    "            # Use basic training method\n",
    "            self.model.fit(X_train, y_train)\n",
    "            print(\"✓ Completed using basic training method\")\n",
    "        \n",
    "        # Validation evaluation\n",
    "        val_pred = self.model.predict(X_val)\n",
    "        val_prob = self.model.predict_proba(X_val)[:, 1]\n",
    "        val_accuracy = accuracy_score(y_val, val_pred)\n",
    "        val_auc = roc_auc_score(y_val, val_prob)\n",
    "        val_f1 = f1_score(y_val, val_pred)\n",
    "        \n",
    "        print(f\"\\nValidation performance:\")\n",
    "        print(f\"Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"AUC: {val_auc:.4f}\")\n",
    "        print(f\"F1-score: {val_f1:.4f}\")\n",
    "        \n",
    "        # Feature importance\n",
    "        if hasattr(self.model, 'feature_importances_'):\n",
    "            self.feature_importance = self.model.feature_importances_\n",
    "            importance_dict = dict(zip(self.feature_names, self.feature_importance))\n",
    "            print(f\"\\nFeature importance:\")\n",
    "            for feature, importance in sorted(importance_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"{feature}: {importance:.4f}\")\n",
    "        \n",
    "        return val_accuracy, val_auc, val_f1\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict\"\"\"\n",
    "        pred = self.model.predict(X)\n",
    "        prob = self.model.predict_proba(X)[:, 1]\n",
    "        return pred, prob\n",
    "    \n",
    "    def cross_validate(self, X, y, cv=5):\n",
    "        \"\"\"Cross validation\"\"\"\n",
    "        print(f\"\\nPerforming {cv}-fold cross validation...\")\n",
    "        cv_scores = cross_val_score(self.model, X, y, cv=cv, scoring='roc_auc')\n",
    "        print(f\"Cross-validation AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        return cv_scores\n",
    "\n",
    "def save_individual_plots(model, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \"\"\"Generate and save individual plots as SVG files\"\"\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    import os\n",
    "    output_dir = \"xgboost_plots\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Saving individual plots to {output_dir}/ directory...\")\n",
    "    \n",
    "    # Predict on all datasets\n",
    "    train_pred, train_prob = model.predict(X_train)\n",
    "    val_pred, val_prob = model.predict(X_val)\n",
    "    test_pred, test_prob = model.predict(X_test)\n",
    "    \n",
    "    # 1. Training loss curve\n",
    "    if model.training_history:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        train_loss = model.training_history.get('train', {}).get('logloss', [])\n",
    "        val_loss = model.training_history.get('validation', {}).get('logloss', [])\n",
    "        \n",
    "        if train_loss and val_loss:\n",
    "            epochs = range(1, len(train_loss) + 1)\n",
    "            ax.plot(epochs, train_loss, 'b-', label='Training loss', linewidth=2)\n",
    "            ax.plot(epochs, val_loss, 'r-', label='Validation loss', linewidth=2)\n",
    "            ax.set_xlabel('Training rounds')\n",
    "            ax.set_ylabel('Logarithmic loss')\n",
    "            ax.set_title('Loss Curve During Training', fontsize=14, fontweight='bold')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Mark best iteration\n",
    "            if hasattr(model.model, 'best_iteration'):\n",
    "                best_iter = model.model.best_iteration\n",
    "                ax.axvline(x=best_iter, color='green', linestyle='--', alpha=0.7, \n",
    "                          label=f'Best round: {best_iter}')\n",
    "                ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/01_training_loss_curve.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"✓ Saved: 01_training_loss_curve.svg\")\n",
    "    \n",
    "    # 2. Feature importance plot\n",
    "    if model.feature_importance is not None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': model.feature_names,\n",
    "            'importance': model.feature_importance\n",
    "        }).sort_values('importance', ascending=True)\n",
    "        \n",
    "        bars = ax.barh(importance_df['feature'], importance_df['importance'], \n",
    "                      color=plt.cm.viridis(np.linspace(0, 1, len(importance_df))))\n",
    "        ax.set_xlabel('Importance Score')\n",
    "        ax.set_title('Feature Importance Ranking', fontsize=14, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, (bar, value) in enumerate(zip(bars, importance_df['importance'])):\n",
    "            ax.text(value + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                   f'{value:.3f}', va='center', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/02_feature_importance.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"✓ Saved: 02_feature_importance.svg\")\n",
    "    \n",
    "    # 3. ROC curves comparison\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Training set ROC\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, train_prob)\n",
    "    auc_train = roc_auc_score(y_train, train_prob)\n",
    "    \n",
    "    # Validation set ROC\n",
    "    fpr_val, tpr_val, _ = roc_curve(y_val, val_prob)\n",
    "    auc_val = roc_auc_score(y_val, val_prob)\n",
    "    \n",
    "    # Test set ROC\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, test_prob)\n",
    "    auc_test = roc_auc_score(y_test, test_prob)\n",
    "    \n",
    "    ax.plot(fpr_train, tpr_train, 'b-', linewidth=2, label=f'Training (AUC = {auc_train:.3f})')\n",
    "    ax.plot(fpr_val, tpr_val, 'g-', linewidth=2, label=f'Validation (AUC = {auc_val:.3f})')\n",
    "    ax.plot(fpr_test, tpr_test, 'r-', linewidth=2, label=f'Test (AUC = {auc_test:.3f})')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random Classifier')\n",
    "    ax.set_xlabel('False Positive Rate (FPR)')\n",
    "    ax.set_ylabel('True Positive Rate (TPR)')\n",
    "    ax.set_title('ROC Curve Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/03_roc_curves.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 03_roc_curves.svg\")\n",
    "    \n",
    "    # 4. Precision-Recall curves\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    precision_train, recall_train, _ = precision_recall_curve(y_train, train_prob)\n",
    "    ap_train = average_precision_score(y_train, train_prob)\n",
    "    \n",
    "    precision_val, recall_val, _ = precision_recall_curve(y_val, val_prob)\n",
    "    ap_val = average_precision_score(y_val, val_prob)\n",
    "    \n",
    "    precision_test, recall_test, _ = precision_recall_curve(y_test, test_prob)\n",
    "    ap_test = average_precision_score(y_test, test_prob)\n",
    "    \n",
    "    ax.plot(recall_train, precision_train, 'b-', linewidth=2, label=f'Training (AP = {ap_train:.3f})')\n",
    "    ax.plot(recall_val, precision_val, 'g-', linewidth=2, label=f'Validation (AP = {ap_val:.3f})')\n",
    "    ax.plot(recall_test, precision_test, 'r-', linewidth=2, label=f'Test (AP = {ap_test:.3f})')\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title('Precision-Recall Curves', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/04_precision_recall_curves.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 04_precision_recall_curves.svg\")\n",
    "    \n",
    "    # 5. Confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, test_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_title('Test Set Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/05_confusion_matrix.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 05_confusion_matrix.svg\")\n",
    "    \n",
    "    # 6. Prediction probability distribution\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    pos_probs = test_prob[y_test == 1]\n",
    "    neg_probs = test_prob[y_test == 0]\n",
    "    \n",
    "    ax.hist(neg_probs, bins=30, alpha=0.7, label='Negative', color='red', density=True)\n",
    "    ax.set_xlabel('Prediction Probability')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Predicted Negative Probability Distribution', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/06-1_Negative_probability_distribution.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 06-1_Negative_probability_distribution.svg\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 6-2. Prediction probability distribution\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    pos_probs = test_prob[y_test == 1]\n",
    "    neg_probs = test_prob[y_test == 0]\n",
    "    \n",
    "    \n",
    "    ax.hist(pos_probs, bins=30, alpha=0.7, label='Positive', color='blue', density=True)\n",
    "    ax.set_xlabel('Prediction Probability')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Predicted Positive Probability Distribution', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/06-2_Positive_probability_distribution.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 06-2_Positive_probability_distribution.svg\")\n",
    "\n",
    "\n",
    "     # 6. Prediction probability distribution\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    pos_probs = test_prob[y_test == 1]\n",
    "    neg_probs = test_prob[y_test == 0]\n",
    "    \n",
    "    ax.hist(neg_probs, bins=30, alpha=0.7, label='Negative', color='red', density=True)\n",
    "    ax.hist(pos_probs, bins=30, alpha=0.7, label='Positive', color='blue', density=True)\n",
    "    ax.set_xlabel('Prediction Probability')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Predicted Probability Distribution', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/06_probability_distribution.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 06_probability_distribution.svg\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # 7. Performance metrics radar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(projection='polar'))\n",
    "    \n",
    "    # Calculate various performance metrics\n",
    "    metrics_names = ['Accuracy', 'AUC', 'Precision', 'Recall', 'F1-score', 'Specificity']\n",
    "    \n",
    "    accuracy_test = accuracy_score(y_test, test_pred)\n",
    "    precision_test = precision_score(y_test, test_pred)\n",
    "    recall_test = recall_score(y_test, test_pred)\n",
    "    f1_test = f1_score(y_test, test_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n",
    "    specificity_test = tn / (tn + fp)\n",
    "    \n",
    "    metrics_values = [accuracy_test, auc_test, precision_test, recall_test, f1_test, specificity_test]\n",
    "    \n",
    "    angles = np.linspace(0, 2 * np.pi, len(metrics_names), endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Close the plot\n",
    "    metrics_values += metrics_values[:1]  # Close the plot\n",
    "    \n",
    "    ax.plot(angles, metrics_values, 'o-', linewidth=2, color='red')\n",
    "    ax.fill(angles, metrics_values, alpha=0.25, color='red')\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(metrics_names)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('Test Set Performance Metrics Radar Chart', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/07_performance_radar.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 07_performance_radar.svg\")\n",
    "    \n",
    "    # 8. Learning curve\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    \n",
    "    for size in train_sizes:\n",
    "        n_samples = int(size * len(X_train))\n",
    "        if n_samples < 10:\n",
    "            continue\n",
    "        \n",
    "        # Subsample training\n",
    "        indices = np.random.choice(len(X_train), n_samples, replace=False)\n",
    "        X_sub = X_train[indices]\n",
    "        y_sub = y_train[indices]\n",
    "        \n",
    "        # Train temporary model\n",
    "        temp_model = xgb.XGBClassifier(\n",
    "            n_estimators=50, max_depth=4, learning_rate=0.1, \n",
    "            random_state=42, eval_metric='logloss', use_label_encoder=False\n",
    "        )\n",
    "        temp_model.fit(X_sub, y_sub)\n",
    "        \n",
    "        # Evaluate\n",
    "        train_pred_temp = temp_model.predict_proba(X_sub)[:, 1]\n",
    "        val_pred_temp = temp_model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        train_scores.append(roc_auc_score(y_sub, train_pred_temp))\n",
    "        val_scores.append(roc_auc_score(y_val, val_pred_temp))\n",
    "    \n",
    "    if train_scores and val_scores:\n",
    "        valid_sizes = train_sizes[:len(train_scores)]\n",
    "        ax.plot(valid_sizes * len(X_train), train_scores, 'b-', linewidth=2, label='Training AUC')\n",
    "        ax.plot(valid_sizes * len(X_train), val_scores, 'r-', linewidth=2, label='Validation AUC')\n",
    "        ax.set_xlabel('Training Sample Size')\n",
    "        ax.set_ylabel('AUC Score')\n",
    "        ax.set_title('Learning Curve', fontsize=14, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/08_learning_curve.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 08_learning_curve.svg\")\n",
    "    \n",
    "    # 9. Feature correlation heatmap\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    feature_data = pd.DataFrame(X_train, columns=[f'X{i+1}' for i in range(X_train.shape[1])])\n",
    "    corr_matrix = feature_data.corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, \n",
    "                cmap = sns.color_palette(\"vlag\", as_cmap=True), \n",
    "                norm=TwoSlopeNorm(vmin=0.9, vcenter=0.95, vmax=1),\n",
    "                center=0, ax=ax,\n",
    "                square=True, fmt='.2f',\n",
    "                linewidths=0.6,         \n",
    "                linecolor='white',\n",
    "                annot_kws={'fontsize':10, 'fontweight':'bold'},\n",
    "                cbar_kws={'shrink':0.8, 'ticks':[-1, -0.5, 0, 0.5, 1]})\n",
    "    ax.set_title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/09_feature_correlation.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 09_feature_correlation.svg\")\n",
    "    \n",
    "    # 10. First decision tree visualization or feature importance pie chart\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    try:\n",
    "        # Try to plot the first decision tree\n",
    "        xgb.plot_tree(model.model, num_trees=0, ax=ax, rankdir='TB')\n",
    "        ax.set_title('XGBoost First Decision Tree Structure', fontsize=14, fontweight='bold')\n",
    "    except:\n",
    "        # If tree plotting fails, show feature importance pie chart\n",
    "        if model.feature_importance is not None:\n",
    "            ax.pie(model.feature_importance, labels=model.feature_names, autopct='%1.1f%%',\n",
    "                  startangle=90, colors=plt.cm.Set3(np.linspace(0, 1, len(model.feature_names))))\n",
    "            ax.set_title('Feature Importance Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/10_tree_or_importance_pie.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 10_tree_or_importance_pie.svg\")\n",
    "    \n",
    "    return {\n",
    "        'train_auc': auc_train,\n",
    "        'val_auc': auc_val,\n",
    "        'test_auc': auc_test,\n",
    "        'test_accuracy': accuracy_test,\n",
    "        'test_f1': f1_test,\n",
    "        'test_precision': precision_test,\n",
    "        'test_recall': recall_test\n",
    "    }\n",
    "\n",
    "def plot_training_progress(model):\n",
    "    \"\"\"Plot detailed training progress\"\"\"\n",
    "    if not model.training_history:\n",
    "        print(\"No training history data available for visualization\")\n",
    "        return\n",
    "    \n",
    "    output_dir = \"xgboost_plots\"\n",
    "    \n",
    "    train_loss = model.training_history.get('train', {}).get('logloss', [])\n",
    "    val_loss = model.training_history.get('validation', {}).get('logloss', [])\n",
    "    \n",
    "    if not train_loss or not val_loss:\n",
    "        print(\"Training history data incomplete\")\n",
    "        return\n",
    "    \n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "    \n",
    "    # Training loss curve\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(epochs, train_loss, 'b-', linewidth=2, label='Training Loss')\n",
    "    ax.plot(epochs, val_loss, 'r-', linewidth=2, label='Validation Loss')\n",
    "    ax.set_xlabel('Training Rounds')\n",
    "    ax.set_ylabel('Logarithmic Loss')\n",
    "    ax.set_title('Training Process Loss Curve', fontweight='bold', fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mark best iteration\n",
    "    if hasattr(model.model, 'best_iteration') and model.model.best_iteration:\n",
    "        best_iter = model.model.best_iteration\n",
    "        ax.axvline(x=best_iter, color='green', linestyle='--', alpha=0.7)\n",
    "        ax.text(best_iter, min(val_loss), f'Best Round: {best_iter}', \n",
    "               rotation=90, verticalalignment='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/11_detailed_training_loss.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 11_detailed_training_loss.svg\")\n",
    "    \n",
    "    # Loss improvement trend\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(epochs[1:], np.diff(train_loss), 'b-', label='Training Loss Improvement', alpha=0.7)\n",
    "    ax.plot(epochs[1:], np.diff(val_loss), 'r-', label='Validation Loss Improvement', alpha=0.7)\n",
    "    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax.set_xlabel('Training Rounds')\n",
    "    ax.set_ylabel('Loss Improvement')\n",
    "    ax.set_title('Loss Improvement Trend', fontweight='bold', fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/12_loss_improvement_trend.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 12_loss_improvement_trend.svg\")\n",
    "    \n",
    "    # Overfitting detection\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    overfitting = np.array(val_loss) - np.array(train_loss)\n",
    "    ax.plot(epochs, overfitting, 'purple', linewidth=2)\n",
    "    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax.fill_between(epochs, overfitting, 0, alpha=0.3, color='purple')\n",
    "    ax.set_xlabel('Training Rounds')\n",
    "    ax.set_ylabel('Validation Loss - Training Loss')\n",
    "    ax.set_title('Overfitting Detection (Higher Gap = More Overfitting)', fontweight='bold', fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/13_overfitting_detection.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 13_overfitting_detection.svg\")\n",
    "    \n",
    "    # Training stability\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    window_size = min(10, len(train_loss) // 4)\n",
    "    if window_size > 1:\n",
    "        train_smooth = pd.Series(train_loss).rolling(window=window_size).std()\n",
    "        val_smooth = pd.Series(val_loss).rolling(window=window_size).std()\n",
    "        \n",
    "        ax.plot(epochs, train_smooth, 'b-', label='Training Loss Volatility', alpha=0.7)\n",
    "        ax.plot(epochs, val_smooth, 'r-', label='Validation Loss Volatility', alpha=0.7)\n",
    "        ax.set_xlabel('Training Rounds')\n",
    "        ax.set_ylabel('Loss Standard Deviation (Rolling Window)')\n",
    "        ax.set_title('Training Stability Analysis', fontweight='bold', fontsize=14)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/14_training_stability.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 14_training_stability.svg\")\n",
    "\n",
    "def analyze_feature_interactions(model, X, feature_names):\n",
    "    \"\"\"Analyze feature interactions\"\"\"\n",
    "    if model.feature_importance is None:\n",
    "        print(\"Model feature importance data not available\")\n",
    "        return\n",
    "    \n",
    "    output_dir = \"xgboost_plots\"\n",
    "    \n",
    "    # Feature importance comparison\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    importance = model.feature_importance\n",
    "    indices = np.argsort(importance)[::-1]\n",
    "    \n",
    "    ax.bar(range(len(importance)), importance[indices], \n",
    "           color=plt.cm.viridis(np.linspace(0, 1, len(importance))))\n",
    "    ax.set_title('Feature Importance Ranking', fontweight='bold', fontsize=14)\n",
    "    ax.set_xlabel('Feature Rank')\n",
    "    ax.set_ylabel('Importance Score')\n",
    "    ax.set_xticks(range(len(importance)))\n",
    "    ax.set_xticklabels([feature_names[i] for i in indices], rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/15_feature_importance_ranking.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 15_feature_importance_ranking.svg\")\n",
    "    \n",
    "    # Feature distribution comparison\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.boxplot([X[:, i] for i in range(X.shape[1])], \n",
    "               labels=[f'X{i+1}' for i in range(X.shape[1])])\n",
    "    ax.set_title('Feature Value Distribution', fontweight='bold', fontsize=14)\n",
    "    ax.set_ylabel('Feature Values')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/16_feature_distribution.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 16_feature_distribution.svg\")\n",
    "    \n",
    "    # Feature correlation network graph\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    feature_data = pd.DataFrame(X, columns=[f'X{i+1}' for i in range(X.shape[1])])\n",
    "    corr_matrix = feature_data.corr()\n",
    "    \n",
    "    # Create network graph layout\n",
    "    G_pos = {}\n",
    "    angle_step = 2 * np.pi / len(feature_names)\n",
    "    for i, name in enumerate(feature_names):\n",
    "        angle = i * angle_step\n",
    "        G_pos[name] = (np.cos(angle), np.sin(angle))\n",
    "    \n",
    "    ax.set_xlim(-1.5, 1.5)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "    \n",
    "    # Draw nodes\n",
    "    for name, (x, y) in G_pos.items():\n",
    "        ax.scatter(x, y, s=1000, c='lightblue', alpha=0.7)\n",
    "        ax.text(x, y, name.split('(')[0], ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    # Draw connection lines (correlations)\n",
    "    for i, name1 in enumerate(feature_names):\n",
    "        for j, name2 in enumerate(feature_names):\n",
    "            if i < j:  # Avoid duplicate drawing\n",
    "                corr = abs(corr_matrix.iloc[i, j])\n",
    "                if corr > 0.3:  # Only show strong correlations\n",
    "                    x1, y1 = G_pos[name1]\n",
    "                    x2, y2 = G_pos[name2]\n",
    "                    ax.plot([x1, x2], [y1, y2], 'r-', alpha=corr, linewidth=corr*3)\n",
    "    \n",
    "    ax.set_title('Feature Correlation Network (Line thickness shows correlation strength)', \n",
    "                 fontweight='bold', fontsize=14)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/17_correlation_network.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 17_correlation_network.svg\")\n",
    "    \n",
    "    # Cumulative importance contribution\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    cumsum_importance = np.cumsum(sorted(importance, reverse=True))\n",
    "    cumsum_importance = cumsum_importance / cumsum_importance[-1] * 100\n",
    "    \n",
    "    ax.plot(range(1, len(cumsum_importance)+1), cumsum_importance, 'bo-', linewidth=2)\n",
    "    ax.axhline(y=80, color='red', linestyle='--', alpha=0.7, label='80% Contribution Line')\n",
    "    ax.axhline(y=95, color='orange', linestyle='--', alpha=0.7, label='95% Contribution Line')\n",
    "    ax.set_xlabel('Number of Features')\n",
    "    ax.set_ylabel('Cumulative Importance Contribution (%)')\n",
    "    ax.set_title('Feature Importance Cumulative Contribution', fontweight='bold', fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, y in enumerate(cumsum_importance):\n",
    "        if i == 0 or i == len(cumsum_importance)-1 or abs(y - 80) < 5 or abs(y - 95) < 5:\n",
    "            ax.annotate(f'{y:.1f}%', (i+1, y), textcoords=\"offset points\", \n",
    "                       xytext=(0,10), ha='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/18_cumulative_importance.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 18_cumulative_importance.svg\")\n",
    "\n",
    "def create_performance_report_table(y_test, test_pred, test_prob):\n",
    "    \"\"\"Create detailed performance report table\"\"\"\n",
    "    output_dir = \"xgboost_plots\"\n",
    "    \n",
    "    # Calculate all metrics\n",
    "    accuracy_test = accuracy_score(y_test, test_pred)\n",
    "    precision_test = precision_score(y_test, test_pred)\n",
    "    recall_test = recall_score(y_test, test_pred)\n",
    "    f1_test = f1_score(y_test, test_pred)\n",
    "    auc_test = roc_auc_score(y_test, test_prob)\n",
    "    ap_test = average_precision_score(y_test, test_prob)\n",
    "    \n",
    "    # Create performance report table\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Create detailed performance report\n",
    "    report = classification_report(y_test, test_pred, output_dict=True)\n",
    "    \n",
    "    report_data = [\n",
    "        ['Class', 'Precision', 'Recall', 'F1-Score', 'Support'],\n",
    "        ['Negative (0)', f\"{report['0']['precision']:.3f}\", f\"{report['0']['recall']:.3f}\", \n",
    "         f\"{report['0']['f1-score']:.3f}\", f\"{report['0']['support']:.0f}\"],\n",
    "        ['Positive (1)', f\"{report['1']['precision']:.3f}\", f\"{report['1']['recall']:.3f}\", \n",
    "         f\"{report['1']['f1-score']:.3f}\", f\"{report['1']['support']:.0f}\"],\n",
    "        ['Macro Average', f\"{report['macro avg']['precision']:.3f}\", f\"{report['macro avg']['recall']:.3f}\", \n",
    "         f\"{report['macro avg']['f1-score']:.3f}\", f\"{report['macro avg']['support']:.0f}\"],\n",
    "        ['Weighted Average', f\"{report['weighted avg']['precision']:.3f}\", f\"{report['weighted avg']['recall']:.3f}\", \n",
    "         f\"{report['weighted avg']['f1-score']:.3f}\", f\"{report['weighted avg']['support']:.0f}\"],\n",
    "        ['', '', '', '', ''],\n",
    "        ['Overall Accuracy', f\"{accuracy_test:.3f}\", '', '', f\"{len(y_test)}\"],\n",
    "        ['AUC Score', f\"{auc_test:.3f}\", '', '', ''],\n",
    "        ['Average Precision', f\"{ap_test:.3f}\", '', '', '']\n",
    "    ]\n",
    "    \n",
    "    table = ax.table(cellText=report_data[1:], colLabels=report_data[0],\n",
    "                    cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.2, 2.0)\n",
    "    \n",
    "    # Set table style\n",
    "    for i in range(len(report_data[0])):\n",
    "        table[(0, i)].set_facecolor('#4CAF50')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    # Highlight performance rows\n",
    "    for i in range(1, 4):  # Negative, Positive, Macro average rows\n",
    "        for j in range(len(report_data[0])):\n",
    "            if i <= 2:  # Class rows\n",
    "                table[(i, j)].set_facecolor('#E8F5E8')\n",
    "            elif i == 3:  # Macro average row\n",
    "                table[(i, j)].set_facecolor('#FFF3CD')\n",
    "    \n",
    "    ax.set_title('XGBoost Model Detailed Performance Report', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/19_performance_report_table.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: 19_performance_report_table.svg\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function\"\"\"\n",
    "    print(\"=== XGBoost Time Series Binary Classification Detailed Analysis ===\\n\")\n",
    "    \n",
    "    # 1. Load data\n",
    "    print(\"1. Loading data...\")\n",
    "    X, y = load_excel_data('DATA-5.xlsx')\n",
    "    \n",
    "    if X is None or y is None:\n",
    "        print(\"Excel data loading failed, using simulated data...！！！！！！！！！\")\n",
    "        X, y = generate_sample_data()\n",
    "    \n",
    "    print(f\"Data dimensions: X={X.shape}, y={y.shape}\")\n",
    "    print(f\"Label distribution: Positive={np.sum(y)} ({100*np.mean(y):.1f}%), Negative={len(y)-np.sum(y)} ({100*(1-np.mean(y)):.1f}%)\")\n",
    "    \n",
    "    # 2. Data preprocessing\n",
    "    print(\"\\n2. Data preprocessing and splitting...\")\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test, scaler = prepare_data(X, y)\n",
    "    \n",
    "    # 3. Create and train XGBoost model\n",
    "    print(\"\\n3. Creating and training XGBoost model...\")\n",
    "    model = XGBoostDetailedModel()\n",
    "    \n",
    "    # Train model\n",
    "    val_acc, val_auc, val_f1 = model.train(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # 4. Cross validation\n",
    "    print(\"\\n4. Performing cross validation...\")\n",
    "    cv_scores = model.cross_validate(X_train, y_train, cv=5)\n",
    "    \n",
    "    # 5. Final test set evaluation\n",
    "    print(\"\\n5. Final test set evaluation...\")\n",
    "    test_pred, test_prob = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "    test_auc = roc_auc_score(y_test, test_prob)\n",
    "    test_f1 = f1_score(y_test, test_pred)\n",
    "    \n",
    "    print(f\"\\n=== Final Test Results ===\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Test AUC: {test_auc:.4f}\")\n",
    "    print(f\"Test F1-Score: {test_f1:.4f}\")\n",
    "    print(f\"Cross-validation AUC Mean: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
    "    \n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_test, test_pred, \n",
    "                               target_names=['Negative', 'Positive']))\n",
    "    \n",
    "    # 6. Comprehensive visualization analysis\n",
    "    print(\"\\n6. Generating detailed visualization analysis...\")\n",
    "    \n",
    "    # Main analysis charts\n",
    "    print(\"Plotting comprehensive analysis charts...\")\n",
    "    results = save_individual_plots(model, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    \n",
    "    # Training process analysis\n",
    "    print(\"Plotting training process analysis...\")\n",
    "    plot_training_progress(model)\n",
    "    \n",
    "    # Feature analysis\n",
    "    print(\"Plotting feature interaction analysis...\")\n",
    "    if model.feature_importance is not None:\n",
    "        analyze_feature_interactions(model, X_train, model.feature_names)\n",
    "    else:\n",
    "        print(\"Skipping feature analysis (feature importance data unavailable)\")\n",
    "    \n",
    "    # Performance report table\n",
    "    print(\"Creating performance report table...\")\n",
    "    create_performance_report_table(y_test, test_pred, test_prob)\n",
    "    \n",
    "    # 7. Model interpretation and recommendations\n",
    "    print(\"\\n=== XGBoost Model Analysis Summary ===\")\n",
    "    print(f\"✓ Model achieved AUC of {test_auc:.3f} on test set, performance is {'Excellent' if test_auc > 0.8 else 'Good' if test_auc > 0.7 else 'Fair'}\")\n",
    "    print(f\"✓ Cross-validation results are stable, AUC standard deviation is {cv_scores.std():.3f}\")\n",
    "    \n",
    "    if model.feature_importance is not None:\n",
    "        most_important = model.feature_names[np.argmax(model.feature_importance)]\n",
    "        print(f\"✓ Most important feature is {most_important}, importance: {np.max(model.feature_importance):.3f}\")\n",
    "        \n",
    "        # Feature importance explanation\n",
    "        importance_ranking = sorted(zip(model.feature_names, model.feature_importance), \n",
    "                                  key=lambda x: x[1], reverse=True)\n",
    "        print(\"\\nFeature Importance Ranking:\")\n",
    "        for i, (feature, importance) in enumerate(importance_ranking, 1):\n",
    "            print(f\"{i}. {feature}: {importance:.3f}\")\n",
    "    else:\n",
    "        print(\"✗ Unable to obtain feature importance information\")\n",
    "    \n",
    "    print(f\"\\nRecommend using this XGBoost model for time series binary classification prediction\")\n",
    "    print(f\"Model training completed, ready for new data prediction\")\n",
    "    print(f\"\\nAll plots have been saved as individual SVG files in the 'xgboost_plots' directory\")\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7964aa-8745-4a75-9900-1ea211a42cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
